from flask import Blueprint, render_template, request, jsonify, flash, Response, stream_with_context
import json 
import traceback
from db_neurohub import db, get_all_researchers
from actual_ai_integration import stream_ai_response_sync

# Blueprint for NeuroHub Ally routes
ally_bp = Blueprint('ally', __name__, template_folder='templates')

@ally_bp.route('/neurohub-ally', methods=['GET'])
def neurohub_ally_page():
    """Renders the NeuroHub Ally AI assistant page."""
    return render_template('neurohub_ally.html', title="NeuroHub Ally - AI Research Assistant")

@ally_bp.route('/api/neurohub-ally/submit', methods=['POST'])
def neurohub_ally_submit():
    """Handles NeuroHub Ally research assistance requests."""
    if request.method == 'POST':
        try:
            # Get form data
            research_query = request.form.get('research_query', '').strip()
            context = request.form.get('context', '')
            experiment_type = request.form.get('experiment_type', '')
            
            if not research_query:
                return jsonify({"error": "Research query is required"}), 400
            
            # TODO: Call the actual AI agent for research assistance
            # For now, return a mock response
            mock_response = f"""
            <h4>Research Query Analysis</h4>
            <p><strong>Your Query:</strong> {research_query}</p>
            
            <h5>Recommended Approach:</h5>
            <ol>
                <li><strong>Experimental Design:</strong> Based on your query, I recommend a within-subjects design with baseline measurements.</li>
                <li><strong>Signal Acquisition:</strong> Use a minimum of 32-channel EEG system with 500Hz sampling rate.</li>
                <li><strong>Protocol Steps:</strong>
                    <ul>
                        <li>5-minute baseline recording</li>
                        <li>Task blocks of 2 minutes each</li>
                        <li>Inter-trial intervals of 30 seconds</li>
                    </ul>
                </li>
                <li><strong>Analysis Pipeline:</strong> Preprocessing → Feature extraction → Statistical analysis</li>
            </ol>
            
            <h5>Key Considerations:</h5>
            <ul>
                <li>Ensure proper electrode impedance (&lt;5kΩ)</li>
                <li>Control for environmental artifacts</li>
                <li>Consider participant fatigue effects</li>
            </ul>
            
            <p><em>This is a mock response. In production, this would be generated by the AI agent based on your specific research needs.</em></p>
            """
            
            return jsonify({
                "success": True,
                "response": mock_response,
                "query": research_query,
                "context": context,
                "experiment_type": experiment_type
            })
            
        except Exception as e:
            print(f"Error in neurohub_ally_submit: {e}")
            traceback.print_exc()
            return jsonify({"error": "An error occurred processing your request"}), 500

@ally_bp.route('/api/neurohub-ally/stream-protocol', methods=['POST'])
def stream_protocol():
    """Stream AI-generated research protocol."""
    def generate():
        try:
            # Get request data
            data = request.get_json()
            research_query = data.get('query', '')
            
            # TODO: Implement actual streaming from AI agent
            # For now, yield mock protocol steps
            steps = [
                "Initializing protocol generation...",
                "Analyzing research requirements...",
                "Designing experimental paradigm...",
                "Calculating sample size requirements...",
                "Generating equipment checklist...",
                "Creating timeline and milestones...",
                "Finalizing protocol document..."
            ]
            
            for step in steps:
                yield f"data: {json.dumps({'type': 'status', 'message': step})}\n\n"
                
            # Final protocol
            protocol = {
                "type": "protocol",
                "content": {
                    "title": "Generated Research Protocol",
                    "sections": [
                        {
                            "heading": "Objective",
                            "content": "To investigate the neural correlates of the specified research question."
                        },
                        {
                            "heading": "Participants",
                            "content": "N=30 healthy adults, aged 18-35, right-handed."
                        },
                        {
                            "heading": "Equipment",
                            "content": "64-channel EEG system, stimulus presentation computer, response pad."
                        },
                        {
                            "heading": "Procedure",
                            "content": "1. Participant screening\n2. Consent and setup\n3. Baseline recording\n4. Task performance\n5. Debriefing"
                        }
                    ]
                }
            }
            
            yield f"data: {json.dumps(protocol)}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )

@ally_bp.route('/api/neurohub-ally/stream', methods=['POST'])
def stream_neurohub_ally():
    """Stream AI responses from connected agents."""
    def generate():
        try:
            # Get request data
            data = request.get_json()
            query = data.get('query', '')
            context = data.get('context', '')
            experiment_type = data.get('experiment_type', '')
            
            # Stream responses from AI agents
            for chunk in stream_ai_response_sync(query, context, experiment_type):
                yield chunk
                
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )

@ally_bp.route('/api/neurohub-ally/stream-analysis-status', methods=['POST'])
def stream_analysis_status():
    """Stream signal analysis progress updates."""
    def generate():
        try:
            # Get request data
            data = request.get_json()
            signal_data_id = data.get('signal_data_id', '')
            
            # TODO: Implement actual analysis streaming
            # For now, yield mock analysis steps
            steps = [
                {"step": "Loading signal data...", "progress": 10},
                {"step": "Applying bandpass filter (0.5-45 Hz)...", "progress": 20},
                {"step": "Detecting and removing artifacts...", "progress": 40},
                {"step": "Extracting features...", "progress": 60},
                {"step": "Running statistical analysis...", "progress": 80},
                {"step": "Generating visualization...", "progress": 90},
                {"step": "Analysis complete!", "progress": 100}
            ]
            
            for step_info in steps:
                yield f"data: {json.dumps({'type': 'progress', 'step': step_info['step'], 'progress': step_info['progress']})}\n\n"
            
            # Final results
            results = {
                "type": "results",
                "content": {
                    "summary": "Signal quality: Good",
                    "artifacts_removed": 12,
                    "snr": 15.3,
                    "dominant_frequency": 10.2,
                    "recommendations": [
                        "Signal quality is suitable for analysis",
                        "Alpha band activity is prominent",
                        "Consider additional preprocessing for channels F3, F4"
                    ]
                }
            }
            
            yield f"data: {json.dumps(results)}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )